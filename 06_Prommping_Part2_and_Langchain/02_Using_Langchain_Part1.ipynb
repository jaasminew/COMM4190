{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1c086e-484c-4210-a59a-d2e428cdcec1",
   "metadata": {},
   "source": [
    "# Using `langchain` (Part 1 - Brief Introduction)\n",
    "\n",
    "* See Chapter 4 of _Prompt Engineering_ book\n",
    "* https://python.langchain.com/docs/get_started/introduction\n",
    "\n",
    "<img src=\"img/langchain_modules.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f994d-8766-4db0-906e-4cdea071d539",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1367d42-7075-47d3-beb1-a9cae1caf558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from operator import itemgetter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2bbb5a-4548-4f8b-9a22-9387cde80651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc4237-8b84-463b-a1e8-1c4c050e2d83",
   "metadata": {},
   "source": [
    "### Set up LLM objects\n",
    "\n",
    "* `langchain` has interfaces to most LLMs\n",
    "   - https://python.langchain.com/docs/integrations/llms/\n",
    "   - This gives a consistent way to switch between different LLMs\n",
    " \n",
    "* Here we can use the Ollama server on the ASC network for open weight models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e8676b-c071-410c-bbdc-d3a0c064c213",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ollama' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ollama \u001b[38;5;241m=\u001b[39m \u001b[43mOllama\u001b[49m(\n\u001b[1;32m      2\u001b[0m         base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://10.30.16.100:11434\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ollama' is not defined"
     ]
    }
   ],
   "source": [
    "ollama = Ollama(\n",
    "        base_url=\"http://10.30.16.100:11434\",\n",
    "        model=\"phi4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894088d0-d6ca-4a10-be4a-dc1b78fb4687",
   "metadata": {},
   "source": [
    "* Can also use OpenAI models with the `ChatOpenAI` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a58f1c2-1d7c-4a77-8926-c8992b71a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e2a54-5d0a-45c4-bc9a-3bfc41b6019f",
   "metadata": {},
   "source": [
    "### Querying a model in `langchain`\n",
    "\n",
    "* Once an LLM object is setup you can query that LLM with the `invoke()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4f53f5-c989-4ce4-99e2-514be34e69eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ollama' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mollama\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ollama' is not defined"
     ]
    }
   ],
   "source": [
    "ollama.invoke(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f0a712-b817-40ca-9671-bd096f295fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am a digital assistant created by OpenAI. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 11, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bed62627-8fdf-4efd-90c0-8d8597c1d2e6-0', usage_metadata={'input_tokens': 11, 'output_tokens': 18, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.invoke(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a89e52-6e60-4ae0-b265-8e15be1f265c",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "\n",
    "* `langchain` attempts to make it easier to build complex prompts and keep history\n",
    "\n",
    "* Here we can set:\n",
    "  1. A system prompt to give the LLM directions on how it should respond.\n",
    "  2. A user prompt (the request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcf617b-7917-459f-af0e-293f5229dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''\n",
    "                    You are Barista in Starbucks. Please ONLY ASSIST with orders for coffee and other Starbucks items. \n",
    "                    DO NOT RESPOND TO OTHER REQUESTS\n",
    "                '''),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad25e30-55d6-4644-99a1-0a48207d2a30",
   "metadata": {},
   "source": [
    "### Chains\n",
    "\n",
    "* The central part of `langchain` is the ability to set up **chains**, i.e. multi-step pathways/flows\n",
    "\n",
    "* https://python.langchain.com/docs/expression_language/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ceacb1-b80a-4cf9-8249-59797e355bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = prompt | ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3483d-377b-42e6-a836-0c5270801d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp=chain1.invoke({'input':'Coffee!'})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a884497e-7d85-4a59-a407-63793cfb0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = prompt | openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b7a6db-377d-4768-bf45-9648ea425964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Sure! What type of coffee would you like to order today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 47, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-6ad65eaf-8a5b-48c4-93a4-8be7bc58e0ee-0' usage_metadata={'input_tokens': 47, 'output_tokens': 14, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "resp=chain2.invoke({'input':'Coffee!'})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dcf1164-715d-4fd2-b9a3-9f6cbfede70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3d8f2ba-0945-48ce-810b-5d1663294029",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain3 = prompt | openai | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b35156c-7baf-486b-b970-c9bd70579a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! What kind of coffee would you like today?\n"
     ]
    }
   ],
   "source": [
    "resp=chain3.invoke({'input':'Coffee!'})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d86840-7219-4231-a2cc-12dfcc1675ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
