{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ff951a-cc40-479f-a8db-4b4ff38ed933",
   "metadata": {},
   "source": [
    "# Attention in LLM Transformer Architecture\n",
    "\n",
    "\n",
    "### Some references\n",
    "\n",
    "* https://towardsdatascience.com/openai-gpt-2-understanding-language-generation-through-visualization-8252f683b2f8\n",
    "* https://jalammar.github.io/illustrated-gpt2/ (very detailed and somewhat technical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3af39-b565-403b-9ead-721838b6cd03",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d444d6-8083-4723-90fb-4e75b62d1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
    "from bertviz import model_view, head_view\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20319248-b3d6-40e2-bbd2-e2091d6a5f74",
   "metadata": {},
   "source": [
    "#### Set up the model and tokenizer for GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849f0d2-7050-482c-8f73-2075d8e37d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cache_dir='/Commjhub/HF_cache'\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = 'gpt2'\n",
    "\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir,\n",
    "                                            return_dict_in_generate=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name, \n",
    "                                  cache_dir=cache_dir,\n",
    "                                  output_attentions=True,\n",
    "                                 )  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d7777d-8226-4138-bdbe-290af6f1eaca",
   "metadata": {},
   "source": [
    "#### Input data to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46aa4b8-ac50-4f37-867c-78c9989effd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text1 = 'The dog on the ship ran'\n",
    "input_text2 = 'The motor on the ship ran'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29898738-1672-4129-8c95-b2cea0830d73",
   "metadata": {},
   "source": [
    "* Tokenize input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b10dfc-4608-4e70-93bd-58cf1a9f2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(input_text1, return_tensors='pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a457d7-a01c-483c-a286-2312c9e1c47f",
   "metadata": {},
   "source": [
    "* Process the input text using the model and retreive attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab0bc2-7b48-48ce-a54e-f65b6e5fdeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model\n",
    "outputs = model(inputs) \n",
    "\n",
    "# Retrieve attention from model outputs\n",
    "attention = outputs[-1]  \n",
    "\n",
    "# Convert input ids to token strings\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ee892-1c17-49f3-ab65-4532d50702aa",
   "metadata": {},
   "source": [
    "* Check tokenization \n",
    "  - Note that GPT2 tokenizer uses a `Ä ` character for whitespace there are some unclear historical reasons for this but it does not effect how the model works or the visualizations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc330fa-1431-44f8-9397-2d31a1265ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217771e-099e-4dbf-b5f5-6b6cfcf23086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf706a-b9c3-49b7-8a29-e36b845a3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab5ebd-d69c-4253-b3dc-e74e0b7b2546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f54ec-d63b-47db-a4d0-e4036ffe0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "  outputs = gpt2(inputs)\n",
    "\n",
    "next_token_logits = outputs.logits[0, -1, :]\n",
    "\n",
    "next_token_probs = torch.softmax(next_token_logits, -1)\n",
    "\n",
    "topk_next_tokens= torch.topk(next_token_probs, 5)\n",
    "\n",
    "for idx, prob in zip(topk_next_tokens.indices, topk_next_tokens.values):\n",
    "    print(f\"{tokenizer.decode(idx): <20}{prob:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e380802-7442-4fd4-8573-7929aef3bb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15972253-e827-4449-98c3-4207b3c33d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645aee2-fb09-4303-a028-4f70f439f3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0794f6-da01-4c8e-a561-861b7cd4dc89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
