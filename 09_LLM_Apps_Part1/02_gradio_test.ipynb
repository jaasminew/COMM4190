{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e627ce7-a928-4978-9a91-b012e8eddd16",
   "metadata": {},
   "source": [
    "# Some examples of building a user interface with `gradio`\n",
    "\n",
    "* https://www.gradio.app/docs/interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea2afb-cfce-495f-8840-51d3e4bec749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbfadb-beee-4136-82d9-a18c198a430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0ccb4-76e1-4c3d-8abb-c9fa0c08c596",
   "metadata": {},
   "source": [
    "### A simple GPT example using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb18d92-a1f0-49c4-a401-f0cc2cd1b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(message, history):\n",
    "    history_openai_format = []\n",
    "    for human, assistant in history:\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages= history_openai_format,\n",
    "        temperature=1.0,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "\n",
    "    partial_message = \"\"\n",
    "    for chunk in response:\n",
    "        if not chunk.choices[0].delta.content is None:\n",
    "            partial_message = partial_message + chunk.choices[0].delta.content\n",
    "            yield partial_message\n",
    "\n",
    "gr.ChatInterface(predict).queue().launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abd339-6b80-4e71-a5a6-c3fd52663113",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface.close(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60cd01-04b2-43b1-98b8-f1c9d2af68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(input_img):\n",
    "\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189], \n",
    "        [0.349, 0.686, 0.168], \n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "\n",
    "app = gr.Interface(transform_image,\n",
    "             gr.Image(),\n",
    "             'image')\n",
    "\n",
    "app.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffd3cb-c78c-45ad-acef-6d7d3820163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1adc8-e24d-4656-afa2-7aecf6dcf96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
