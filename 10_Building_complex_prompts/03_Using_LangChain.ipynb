{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21193234-110a-4bc8-aa90-dead04c9e570",
   "metadata": {},
   "source": [
    "# LangChain (and LangGraph)\n",
    "\n",
    "\n",
    "<img src=\"img/langchain_book.jpeg\" width=\"200px\"/>\n",
    "\n",
    "### Some references\n",
    "\n",
    "* https://learning.oreilly.com/library/view/learning-langchain/9781098167271/preface01.html\n",
    "\n",
    "* https://learning.oreilly.com/library/view/learning-langchain/9781098167271/ch01.html\n",
    "\n",
    "* https://github.com/vinodvpillai/langchain-conversation-memory-examples\n",
    "\n",
    "* https://www.ibm.com/think/tutorials/prompt-chaining-langchain\n",
    "\n",
    "* https://datascientistsdiary.com/langchain-vs-langgraph/\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f12d1-faae-48dd-9199-bcc1df4e2c11",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba3a1ff-d751-46a4-817e-95689da30e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1d58a-2e8c-45da-a9ec-139da9e4ab26",
   "metadata": {},
   "source": [
    "## Example 1: Adding memory to simple chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95aa029a-beb9-4484-aaf1-cb8c82c626cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306552/2773693126.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
      "/tmp/ipykernel_306552/2773693126.py:11: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  legacy_chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Nice to meet you, Timon! How can I assist you today?', 'chat_history': [HumanMessage(content='My name is Timon', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Timon! How can I assist you today?', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "----\n",
      "\n",
      "{'text': 'Those are some lovely names! If you would like, I can provide some information or assistance related to these names. Just let me know how I can help!', 'chat_history': [HumanMessage(content='My name is Timon', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Timon! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Here are some other names: Amina, Akira, Carlos, Fatima, Ji-hoon, Leila, Maria, Nia, Priya, Raphael, Sanaa, Sofia, Tao, Victor, Yara', additional_kwargs={}, response_metadata={}), AIMessage(content='Those are some lovely names! If you would like, I can provide some information or assistance related to these names. Just let me know how I can help!', additional_kwargs={}, response_metadata={})]}\n",
      "\n",
      "----\n",
      "\n",
      "{'text': 'Your name is Timon.', 'chat_history': [HumanMessage(content='My name is Timon', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Timon! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Here are some other names: Amina, Akira, Carlos, Fatima, Ji-hoon, Leila, Maria, Nia, Priya, Raphael, Sanaa, Sofia, Tao, Victor, Yara', additional_kwargs={}, response_metadata={}), AIMessage(content='Those are some lovely names! If you would like, I can provide some information or assistance related to these names. Just let me know how I can help!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What was my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Timon.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", \n",
    "                                  return_messages=True)\n",
    "\n",
    "legacy_chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "result1 = legacy_chain.invoke({\"text\": \"My name is Timon\"})\n",
    "\n",
    "print(result1)\n",
    "\n",
    "print('\\n----\\n')\n",
    "\n",
    "result2 = legacy_chain.invoke({\"text\": \"Here are some other names: Amina, Akira, Carlos, Fatima, Ji-hoon, Leila, Maria, Nia, Priya, Raphael, Sanaa, Sofia, Tao, Victor, Yara\"})\n",
    "\n",
    "print(result2)\n",
    "\n",
    "print('\\n----\\n')\n",
    "\n",
    "result3 = legacy_chain.invoke({\"text\": \"What was my name?\"})\n",
    "\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865caa10-342b-4e06-9726-47007f634325",
   "metadata": {},
   "source": [
    "## Example 2: A multi-stage chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1627f4c-6b41-4212-9618-78e6b4e96cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    \"generate a {attribute} color. Return the name of the color and nothing else:\"\n",
    ")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what is a fruit of color: {color}. Return the name of the fruit and nothing else:\"\n",
    ")\n",
    "prompt3 = ChatPromptTemplate.from_template(\n",
    "    \"what is a country with a flag that has the color: {color}. Return the name of the country and nothing else:\"\n",
    ")\n",
    "prompt4 = ChatPromptTemplate.from_template(\n",
    "    \"What is the color of {fruit} and the flag of {country}?\"\n",
    ")\n",
    "\n",
    "model_parser = model | StrOutputParser()\n",
    "\n",
    "color_generator = (\n",
    "    {\"attribute\": RunnablePassthrough()} | prompt1 | {\"color\": model_parser}\n",
    ")\n",
    "color_to_fruit = prompt2 | model_parser\n",
    "color_to_country = prompt3 | model_parser\n",
    "question_generator = (\n",
    "    color_generator | {\"fruit\": color_to_fruit, \"country\": color_to_country} | prompt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1387752-29e0-4605-89f2-11d391719815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='What is the color of Banana and the flag of Colombia?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_generator.invoke(\"happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2eb81c-ddb4-4d08-9a8e-5680666d6aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efa7c997-b6ae-4bac-a6d8-7116ad4e9984",
   "metadata": {},
   "source": [
    "## Example 3 - Analyzing review text\n",
    "\n",
    "* Adapted from: https://www.ibm.com/think/tutorials/prompt-chaining-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e4b9c3-5ba0-4dd9-9819-250651b30057",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_prompt = PromptTemplate(\n",
    "    input_variables = [\"text\"],\n",
    "    template=\"Extract the most important keywords from the following text:\\n{text}\\n\\nKeywords:\"\n",
    ")\n",
    "\n",
    "sentiment_prompt = PromptTemplate(\n",
    "    input_variables = [\"keywords\"],\n",
    "    template=\"Using the following keywords, summarize the sentiment:\\nKeywords: {keywords}\\n\\nSentiment Summary:\"\n",
    ")\n",
    "\n",
    "\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables = [\"sentiment_summary\"],\n",
    "    template=\"Refine the following sentiment summary to make it concise and precise:\\n{sentiment_summary}\\n\\nRefined summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4656d2-423a-4cc3-bc0c-29ceb44ecbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d11647-1f5a-42b3-8cf4-c0d6add85768",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_chain = LLMChain(\n",
    "    llm = model,\n",
    "    prompt = keyword_prompt,\n",
    "    output_key = \"keywords\",\n",
    "    verbose = VERBOSE\n",
    ")\n",
    "\n",
    "sentiment_chain = LLMChain(\n",
    "    llm = model,\n",
    "    prompt = sentiment_prompt,\n",
    "    output_key = \"sentiment_summary\",\n",
    "    verbose = VERBOSE\n",
    ")\n",
    "\n",
    "refine_chain = LLMChain(\n",
    "    llm = model,\n",
    "    prompt = refine_prompt,\n",
    "    output_key = \"refined_summary\",\n",
    "    verbose = VERBOSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6b8cb6-d2b7-463f-834f-8874826284a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = SequentialChain(\n",
    "        chains = [keyword_chain, sentiment_chain, refine_chain],\n",
    "        input_variables=[\"text\"],\n",
    "        output_variables=[\"refined_summary\"],\n",
    "        verbose=VERBOSE,\n",
    "        return_all=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c091cc03-779b-4a07-8d59-1bf8be846f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review1 = '''\n",
    "Somewhere in the past year, ChatGPT has gone from \"cool, interesting, amusing\" to a massively valuable work assistant capable of writing Python scripts, analysing data, and doing lots, lots, more. The key to this? The rapid evolution of OpenAI's GPT models and making my first forays into prompt engineering.\n",
    "\n",
    "If I thought I was getting good, though, this book took me reminded me that I'm just scratching the surface. Halfway through the first chapter I was already furiously scribbling notes in the margins for what I could do better with my prompt writing and by the end of the text I felt like I had gotten a very good grounding - not just in GPTs specifically but in the bigger picture of how these hugely powerful tools were trained and came to maturity.\n",
    "\n",
    "I imagine that few will argue with my assertion that there is lots of hyperbole and \"noise\" in the AI space right now which, as ever, makes it hard to pick out the signal from the noise. Which is precisely why I sought out an O'Reilly title and I'm very glad that I did.\n",
    "\n",
    "Thorough, excellent, and I hope that this edition will be the first of many. As this rapidly maturing field scales and matures I think that prompt engineering will be an essential discipline to master. Pick up this text to get a good foothold on things.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9477be-ce44-4c0c-963f-9501065b9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "review2 = '''\n",
    "I applaud the authors for putting forth a comprehensive introduction in a rapidly evolving space. I absorbed a lot, helpful as I was developing a prototype — using open source methods.\n",
    "\n",
    "And that’s where I was disappointed. The LLM and examples are highly adapted to OpenAI’s GPT-x and the bulky LangChain framework, something not obvious until you dig in to the book. Sure, this may be where newbie demand was when the authors began writing. But as the open source models and OpenAI alternatives gain speed (e.g. Llama 3.1, Groq, etc.) this book may quickly need an updated and expanded version to stay relevant.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb4eb637-f758-4bbf-b076-0ce5897793e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306552/985787591.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = workflow.run({\"text\": review2})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mExtract the most important keywords from the following text:\n",
      "\n",
      "I applaud the authors for putting forth a comprehensive introduction in a rapidly evolving space. I absorbed a lot, helpful as I was developing a prototype — using open source methods.\n",
      "\n",
      "And that’s where I was disappointed. The LLM and examples are highly adapted to OpenAI’s GPT-x and the bulky LangChain framework, something not obvious until you dig in to the book. Sure, this may be where newbie demand was when the authors began writing. But as the open source models and OpenAI alternatives gain speed (e.g. Llama 3.1, Groq, etc.) this book may quickly need an updated and expanded version to stay relevant.\n",
      "\n",
      "\n",
      "Keywords:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUsing the following keywords, summarize the sentiment:\n",
      "Keywords: - Authors\n",
      "- Comprehensive introduction\n",
      "- Evolving space\n",
      "- Prototype\n",
      "- Open source methods\n",
      "- LLM\n",
      "- OpenAI\n",
      "- GPT-x\n",
      "- LangChain framework\n",
      "- Newbie demand\n",
      "- Open source models\n",
      "- Alternatives\n",
      "- Llama 3.1\n",
      "- Groq\n",
      "- Updated version\n",
      "- Expanded version\n",
      "- Stay relevant\n",
      "\n",
      "Sentiment Summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mRefine the following sentiment summary to make it concise and precise:\n",
      "The sentiment reflected by the keywords suggests a positive and optimistic outlook on the developments in the field of natural language processing and AI. There is an emphasis on a comprehensive introduction to evolving technologies, particularly regarding large language models (LLMs) like OpenAI’s GPT-x and alternatives such as Llama 3.1 and Groq. The mention of open source methods and the LangChain framework indicates a collaborative and inclusive environment, catering to newbie demand. The words \"updated version\" and \"expanded version\" imply a commitment to continual improvement and innovation, underscoring the need for individuals and organizations to stay relevant in this fast-paced field. Overall, the sentiment is one of enthusiasm for progress and accessibility in AI technologies.\n",
      "\n",
      "Refined summary\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The sentiment reflects a positive outlook on advancements in natural language processing and AI, highlighting large language models (LLMs) like OpenAI’s GPT-x, Llama 3.1, and Groq. The focus on open-source methods and the LangChain framework suggests a collaborative environment catering to newcomers. Terms like \"updated version\" and \"expanded version\" indicate a commitment to continuous improvement and innovation, emphasizing the need for individuals and organizations to stay relevant in this rapidly evolving field. Overall, the sentiment conveys enthusiasm for progress and accessibility in AI technologies.\n"
     ]
    }
   ],
   "source": [
    "result = workflow.run({\"text\": review2})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87659b2d-ed04-419f-a06b-3cfbe6a1ab40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment reflects a positive outlook on advancements in natural language processing and AI, highlighting large language models (LLMs) like OpenAI’s GPT-x, Llama 3.1, and Groq. The focus on open-source methods and the LangChain framework suggests a collaborative environment catering to newcomers. Terms like \"updated version\" and \"expanded version\" indicate a commitment to continuous improvement and innovation, emphasizing the need for individuals and organizations to stay relevant in this rapidly evolving field. Overall, the sentiment conveys enthusiasm for progress and accessibility in AI technologies.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c401533-9489-43f3-b9a0-d64f0a111d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mExtract the most important keywords from the following text:\n",
      "\n",
      "I applaud the authors for putting forth a comprehensive introduction in a rapidly evolving space. I absorbed a lot, helpful as I was developing a prototype — using open source methods.\n",
      "\n",
      "And that’s where I was disappointed. The LLM and examples are highly adapted to OpenAI’s GPT-x and the bulky LangChain framework, something not obvious until you dig in to the book. Sure, this may be where newbie demand was when the authors began writing. But as the open source models and OpenAI alternatives gain speed (e.g. Llama 3.1, Groq, etc.) this book may quickly need an updated and expanded version to stay relevant.\n",
      "\n",
      "\n",
      "Keywords:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUsing the following keywords, summarize the sentiment:\n",
      "Keywords: 1. Authors\n",
      "2. Comprehensive introduction\n",
      "3. Rapidly evolving space\n",
      "4. Prototype\n",
      "5. Open source methods\n",
      "6. LLM (Large Language Models)\n",
      "7. OpenAI\n",
      "8. GPT-x\n",
      "9. LangChain framework\n",
      "10. Newbie demand\n",
      "11. Open source models\n",
      "12. OpenAI alternatives\n",
      "13. Llama 3.1\n",
      "14. Groq\n",
      "15. Updated version\n",
      "16. Expanded version\n",
      "17. Relevant\n",
      "\n",
      "Sentiment Summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mRefine the following sentiment summary to make it concise and precise:\n",
      "The sentiment surrounding the keywords suggests a positive and optimistic outlook on the advancements in the field of Large Language Models (LLMs) and open-source methods. There is a clear emphasis on the need for a comprehensive introduction to this rapidly evolving space, indicating a growing interest among newcomers (newbie demand) who seek accessible resources. The mention of various developments, such as the updated and expanded versions of models like GPT-x, Llama 3.1, and alternatives to OpenAI emphasizes the dynamic nature of the technology, with an increasing variety of options available through frameworks like LangChain and tools from organizations like Groq. Overall, the sentiment reflects excitement about innovation, accessibility, and the collaborative spirit within the community, highlighting the relevance of ongoing projects and tools.\n",
      "\n",
      "Refined summary\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sentiment surrounding Large Language Models (LLMs) and open-source methods is notably positive and optimistic. There is a growing interest among newcomers for accessible resources, indicating a demand for comprehensive introductions to this rapidly evolving field. Developments like updated versions of GPT-x, Llama 3.1, and alternatives to OpenAI demonstrate the dynamic nature of technology, with a wider range of options available through frameworks like LangChain and tools from organizations like Groq. Overall, the sentiment reflects excitement about innovation, accessibility, and collaboration within the community, underscoring the importance of ongoing projects and tools.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.run({\"text\": review2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66c64f-7764-4522-9435-97ee105e5c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
