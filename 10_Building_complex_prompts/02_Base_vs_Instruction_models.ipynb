{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d95a18f-8f20-40f2-81b5-0dc507eb7653",
   "metadata": {},
   "source": [
    "# Comparing a base model to an instruction finetuned model\n",
    "\n",
    "![](img/base_vs_instruct.jpg)\n",
    "\n",
    "* https://medium.com/@yananchen1116/clearance-of-the-confusion-llms-base-and-instruct-version-48d4ef402591"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eec343-46d5-4665-8713-ae0c7035afff",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426515ce-6af5-4da9-8c44-f82b3ac733a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e58355f-cc77-4b9b-8931-18d2c2ff9d75",
   "metadata": {},
   "source": [
    "#### Models\n",
    "\n",
    "* Here we will compare two versions of Meta's `llama3.2` model using the quantized version available through Ollama (See ollama.ai for details on using LLMs on your own machine)\n",
    "\n",
    "* https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/\n",
    "\n",
    "* https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md\n",
    "\n",
    "* Huggingface card's for the two models:\n",
    "  1. `llama3.2.1B` -  base model (NO FINETUNING or ALIGNMENT)\n",
    "     - https://huggingface.co/meta-llama/Llama-3.2-1B\n",
    "  2. `llama3.2.1B-it` - instruction finetuned\n",
    "     - https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\n",
    "\n",
    "\n",
    "> **Model Architecture**: Llama 3.2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for helpfulness and safety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82a212-a570-473e-b295-2a17d8bb9c60",
   "metadata": {},
   "source": [
    "#### Setup `langchain` LLM objects for each model\n",
    "\n",
    "* `langchain` has an `OllamaLLM` submodule to make using ollama served models easy to use and interoperable with other parts of a chain and other LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6277edd7-07a8-4c97-8ade-d00ad7d7cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_2_instruct = OllamaLLM(\n",
    "        base_url=\"http://10.30.16.100:11434\",\n",
    "        model=\"llama3.2:1b-instruct-q8_0\")\n",
    "\n",
    "llama3_2_base = OllamaLLM(\n",
    "        base_url=\"http://10.30.16.100:11434\",\n",
    "        model=\"llama3.2:1b-text-q8_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc543e-09fb-4e7a-a6ac-e384138f7fb9",
   "metadata": {},
   "source": [
    "### Compare response from base and instruct models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd0051-0444-411c-9e10-10e2b274d75b",
   "metadata": {},
   "source": [
    "#### Prompts\n",
    "\n",
    "* Use Wh-question prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ad87b6-e7a9-4d3b-a142-d030abd19aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"Who is the president of the United States?\"\n",
    "prompt2 = \"What is the capital of France?\"\n",
    "prompt3 = \"Why is the sky blue?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284cae1a-4b41-4b3c-b6dc-e4d3e084b5ed",
   "metadata": {},
   "source": [
    "#### `invoke` function\n",
    "\n",
    "* All `langchain` LLM objects have an `invoke` function that will provide synchronous response from the LLM to a passed prompt. Output only given once response is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5ee8b4-8328-414f-ab6c-4b5959069302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is there a presidential election this year?\n",
      "Is the US in an economic recession or on its way to one?\n",
      "What's happening with the debt ceiling and is it a cause for concern right now?\n",
      "Why are you so afraid that someone will be put in office who will take away all your liberties?\n",
      "How much have we been lied to over the years about Iraq?\n"
     ]
    }
   ],
   "source": [
    "base_resp1 = llama3_2_base.invoke(prompt1)\n",
    "\n",
    "print(base_resp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d56c5-cc0e-4876-85f8-0e0aa7637a55",
   "metadata": {},
   "source": [
    "* **NOTE** this isn't really answering the question but continuing to generate text that would most likely continue after the question `'Who is the president of the United States?'` in examples seen in the pre-training data.\n",
    "\n",
    "* Compare with the response from the **INSTRUCTION FINE-TUNED** version of the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3365601b-7a06-4e55-a492-5cace97b5204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in 2023, the President of the United States is Joe Biden. However, please note that political positions and information can change over time due to elections, resignations, or other events that may affect the administration. If you're looking for the most current information, I recommend checking a reliable news source or the official website of the White House.\n"
     ]
    }
   ],
   "source": [
    "instruct_resp1 = llama3_2_instruct.invoke(prompt1)\n",
    "\n",
    "print(instruct_resp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d27ff-0ba2-4929-b0c4-1446df82a56d",
   "metadata": {},
   "source": [
    "* **NOTE**\n",
    "  1. Shorter response that directly relates to the question in the prompt. Answers to short questions like `'Who is the president of the United States?'` are generally only 1 or 2 sentences long.\n",
    "  2. The alignment of the model provides context and time-limitation to the response of April 2023 when training was completed.\n",
    "  3. Disclaimer included in response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130df67d-0e04-47c4-a91b-5f517fd81967",
   "metadata": {},
   "source": [
    "### Streaming response from LLM object\n",
    "\n",
    "* `langchain` LLM objects also include a `stream` function that allow you to receive and process responses a chunk at a time.\n",
    "* This can be by synchronous (wait for chunk) or asynchronous (set up a call back and receive a token at a time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068e9b9-27e9-4994-9646-49a92852a040",
   "metadata": {},
   "source": [
    "#### Responses to `What is the capital of France?` from both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aff532e-989f-41ae-980e-9c6d2dfe5634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France?\n"
     ]
    }
   ],
   "source": [
    "print(prompt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e611d87-f662-4fe9-9db1-a9deccabdd93",
   "metadata": {},
   "source": [
    "* **Base `llama3.2-1b`**\n",
    "  - try rerunning the cell a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27e09bd-11cb-4a09-b6d2-5e6663190f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A. Austin B. Nashville C. New York D. Washington, D.C.\n",
      "A. Paris\n",
      "B. Philadelphia\n",
      "C. Denver\n",
      " Boston\n",
      "Answer: A"
     ]
    }
   ],
   "source": [
    "for chunk in llama3_2_base.stream(prompt2):\n",
    "    print(chunk, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9907e9-68ad-466e-bba6-10d9cd7c4109",
   "metadata": {},
   "source": [
    "* **Instruction finetuned `llama3.2-1b-Instruct`**\n",
    "  - try rerunning the cell a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f09552f-f601-4904-9c4f-2aebc44f781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris."
     ]
    }
   ],
   "source": [
    "for chunk in llama3_2_instruct.stream(prompt2):\n",
    "    print(chunk, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8b270-6d61-43d6-9425-87048effeca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaaad878-016a-4148-aba3-54441543169e",
   "metadata": {},
   "source": [
    "#### Responses to `Why is the sky blue?` from both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92106e48-6f80-44bc-b3e7-88e0a901fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is the sky blue?\n"
     ]
    }
   ],
   "source": [
    "print(prompt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1eac4-947d-47ba-9709-ae1eae2f2b4c",
   "metadata": {},
   "source": [
    "* **Base `llama3.2-1b`**\n",
    "  - try rerunning the cell a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61166d3b-a100-4db5-ad8b-7874e709bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What about a rainbow?\n",
      " still ask. It's because they don't fully understand or know how to answer them.\n",
      "To find out, take note of how the color changes as you move towards the horizon (or the sun). As the light gets dimmer, your vision gets dimmer too. At the end is a twilight zone where all colors are mixed together and it turns into grayish blue. When all the light disappears, that's when the sky starts to turn blue.\n",
      " is blue has been debated for centuries. Scientists have tried their best to find out what causes this phenomenon but so far no one has come up with a conclusive answer.\n",
      " facts we know about it:nd some\n",
      " of three layers - the outer layer (clouds), middle layer (space between clouds), inner layer (atmosphere). The sunlight reflects off each layer depending on their color. Blue light is the most absorbed by water vapor in the atmosphere so that makes up half of its color.\n",
      "2) Water vapor also absorbs some wavelengths of red, green and yellow light but not blue since there are no visible lines where these colors overlap. So when you see a lot of sunlight coming from behind you (like sunlight from outside), it will appear brighter because all those high energy photons reflect off the water molecules in clouds before getting absorbed by earth's atmosphere.\n",
      " time, after sunset or sunrise hours, everything appears darker since there is no light source anymore. So what makes up most of our night sky? The stars! They shine on their own without needing any form of lighting system. That means that if you go outside at midnight or early morning hours and look upwards towards the heavens - your eyes will adjust to darkness much faster compared to during daytime when there are lots of artificial lights around.\n",
      " our night sky with something like a rainbow, what's special about this one? Unlike other rainbows where the colors change in sequence starting from red and moving towards violet; ours is more symmetric - which means it doesn't end at blackness but extends infinitely downwards until reaching zero brightness point. This gives us a unique quality that can only be found here!\n",
      " thing worth mentioning about this phenomenon of blue sky is its impact on our lives! If you've ever had trouble seeing objects at night due to low visibility then try looking upwards towards the heavens during evening or morning hours when all lights are off - chances are good that there won't be any problem anymore because now everything looks clearer!\n",
      " if you're wondering why people call it \"blue sky\"? It doesn't happen by accident! When clouds start to form over an area with heavy precipitation (rain), they will contain less water than normal due its ability to absorb sunlight energy. This means that there won't be as much light reflecting off those layers making them look darker at times - hence giving rise towards blue colored sky!\n",
      " in the distance, remember that it isn’t just another sunset but rather a magical sight that can bring joy and happiness into anyone’s life who looks up towards those beautiful stars!"
     ]
    }
   ],
   "source": [
    "for chunk in llama3_2_base.stream(prompt3):\n",
    "    print(chunk, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db48e28-eaa7-43e9-a532-a756db624058",
   "metadata": {},
   "source": [
    "* **Instruction finetuned `llama3.2-1b-Instruct`**\n",
    "  - try rerunning the cell a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16152f29-4dfc-4a5c-820d-14602fcce9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to the human eye because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh. He discovered that when light travels through a gas like air, it scatters in all directions, but more efficiently in the direction of the sun.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      " and encounters tiny molecules of gases like nitrogen (N2) and oxygen (O2).\n",
      " These molecules scatter the shorter, blue wavelengths of light more than the longer, red wavelengths.\n",
      " This scattering effect is more pronounced because blue light has a smaller wavelength than red light.\n",
      " As a result, about 7% of the sunlight that enters the Earth's atmosphere is scattered in all directions, leaving about 93% of it to be reflected back to our eyes from the top and bottom of the atmosphere.\n",
      "\n",
      " during the day, especially during sunrise and sunset when the angle of the sun's rays hits the atmosphere at a more shallow angle. The scattered light is what gives the sky its blue appearance.\n",
      "\n",
      "Keep in mind that the sky can take on different colors depending on various factors, such as:\n",
      "\n",
      "* Dust particles in the air: These can scatter light in a way that makes the sky appear hazy or gray.\n",
      " change the color of the sky.se can also scatter light and\n",
      " phenomena can alter the scattering of light and affect the color of the sky.\n",
      "\n",
      " the most dominant color of the sky due to Rayleigh scattering."
     ]
    }
   ],
   "source": [
    "for chunk in llama3_2_instruct.stream(prompt3):\n",
    "    print(chunk, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755049e-c13e-4778-a7f3-b5669baf6d2c",
   "metadata": {},
   "source": [
    "## Domain finetuning\n",
    "\n",
    "- https://huggingface.co/blog/ImranzamanML/fine-tuning-1b-llama-32-a-comprehensive-article\n",
    "- https://www.llama.com/docs/how-to-guides/fine-tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454a27f-9c8a-4209-895c-f985e4aa4fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
